{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>The user interface has evolved dramatically over the years, bringing us incredible benefits in terms of time efficiency. For instance, in the past, we had to manually dial a number to call someone with an old phone. But now, with buttons, touch screens and even voice commands, we can make calls in a matter of seconds.</p> <p>In many machine learning projects, we face the challenge of comparing different models, datasets and frameworks. This can be very tedious\ud83d\ude12 and time-consuming\u23f3. Because each dataset has its own format, each framework has its own configuration and each model has its own input and output even they are dealing with the exact same task \ud83d\ude20.</p> <p>When it comes to MLOps (machine learning operations), you need to be able to keep up with all the new ideas and SOTA models in deep learning as quickly as possible\ud83d\ude80.</p> <p>Here comes Waffle\ud83e\uddc7. Waffle is a framework that lets you use lots of different deep learning tools through just one interface. It's user-friendly and easy\ud83d\ude0a. We believe it's going to make a big revolution in the AI industry.</p> <p></p> <p>Experience the power\ud83d\udcaa of revolution that Waffle\ud83e\uddc7 brings to you, unlocking limitless possibilities for your machine learning projects.</p>"},{"location":"tutorials/","title":"Welcome to Waffle Tutorial \ud83e\uddc7\ud83e\uddc7\ud83e\uddc7","text":"<p>In this tutorial, we will learn how to use <code>Waffle</code>: </p> <ul> <li>how to Prepare Dataset</li> <li>how to Using Waffle Hub</li> <li>how to Sample useful data</li> <li>how to Visualization</li> </ul>"},{"location":"tutorials/active_filter/","title":"Active Filter","text":"In\u00a0[1]: Copied! <pre>from waffle_hub.hub.adapter.ultralytics import UltralyticsHub\n\nhub = UltralyticsHub.load(\"ultralytics_mnist_detection\")\n</pre> from waffle_hub.hub.adapter.ultralytics import UltralyticsHub  hub = UltralyticsHub.load(\"ultralytics_mnist_detection\") <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:16: UserWarning: \n            torch 1.13.1+cu117 has not been tested.\n            We recommend you to use one of ['1.13.1']\n            \n  warnings.warn(\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:56: UserWarning: \n                ultralytics 8.0.91 has not been tested.\n                We recommend you to use one of ['8.0.87']\n                \n  warnings.warn(\n</pre> In\u00a0[1]: Copied! <pre>from waffle_menu.active_learning import RandomSampling, PL2NSampling\n</pre> from waffle_menu.active_learning import RandomSampling, PL2NSampling <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:16: UserWarning: \n            torch 1.13.1+cu117 has not been tested.\n            We recommend you to use one of ['1.13.1']\n            \n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>RandomSampling(\n    seed=1234\n).sample(\n    image_dir=\"mnist/images\",\n    num_images=5,\n    result_dir=\"random_sampled\",\n    save_images=True\n)\n</pre> RandomSampling(     seed=1234 ).sample(     image_dir=\"mnist/images\",     num_images=5,     result_dir=\"random_sampled\",     save_images=True ) <pre>4it [00:00, 91.17it/s]\n</pre> Out[3]: <pre>&lt;waffle_menu.active_learning.active_learning.ActiveLearningCallback at 0x7fc993964430&gt;</pre> In\u00a0[4]: Copied! <pre>PL2NSampling(\n    hub=hub\n).sample(\n    image_dir=\"mnist/images\",\n    num_images=5,\n    result_dir=\"PL2N_sampled\",\n    save_images=True\n)\n</pre> PL2NSampling(     hub=hub ).sample(     image_dir=\"mnist/images\",     num_images=5,     result_dir=\"PL2N_sampled\",     save_images=True ) <pre>4it [00:00,  7.69it/s]\n</pre> Out[4]: <pre>&lt;waffle_menu.active_learning.active_learning.ActiveLearningCallback at 0x7fc99392e880&gt;</pre> In\u00a0[5]: Copied! <pre>import PIL.Image\nfrom pathlib import Path\n</pre> import PIL.Image from pathlib import Path In\u00a0[6]: Copied! <pre># display n images in a row with PIL\ndef display_images(images):\n    images = [PIL.Image.open(image) for image in images]\n    widths, heights = zip(*(i.size for i in images))\n    total_width = sum(widths)\n    max_height = max(heights)\n    new_im = PIL.Image.new(\"RGB\", (total_width, max_height))\n    x_offset = 0\n    for im in images:\n        new_im.paste(im, (x_offset, 0))\n        x_offset += im.size[0]\n    return new_im\n</pre> # display n images in a row with PIL def display_images(images):     images = [PIL.Image.open(image) for image in images]     widths, heights = zip(*(i.size for i in images))     total_width = sum(widths)     max_height = max(heights)     new_im = PIL.Image.new(\"RGB\", (total_width, max_height))     x_offset = 0     for im in images:         new_im.paste(im, (x_offset, 0))         x_offset += im.size[0]     return new_im In\u00a0[7]: Copied! <pre>display_images(list(Path(\"random_sampled/images\").glob(\"*.png\")))\n</pre> display_images(list(Path(\"random_sampled/images\").glob(\"*.png\"))) Out[7]: In\u00a0[8]: Copied! <pre>display_images(list(Path(\"PL2N_sampled/images\").glob(\"*.png\")))\n</pre> display_images(list(Path(\"PL2N_sampled/images\").glob(\"*.png\"))) Out[8]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/active_filter/#active-sampling-with-hub","title":"Active Sampling with hub\u00b6","text":"<p>Active Learning is a data sampling technique that allows you to select the most informative samples from a large unlabeled dataset. This is done by training a model on a small subset of labeled data and then using the model to predict the labels of the unlabeled data. The samples with the highest prediction uncertainty are then selected for labeling. This process is repeated until the model is trained on all the data. The model is then retrained on the entire dataset. This process is called active learning. </p> <p>You can get more information about active learning from our Blog Post. </p> <p>This is our private feature. If you want to use it, please contact us. </p>"},{"location":"tutorials/active_filter/#load-trained-hub","title":"Load trained Hub\u00b6","text":"<p>To use active learning, you need to load the trained hub.</p>"},{"location":"tutorials/active_filter/#import-sampling-methods","title":"Import Sampling Methods\u00b6","text":"<p>This tutorial uses the following sampling methods: </p> <ul> <li>Random Sampling</li> <li>PL2N Sampling</li> </ul>"},{"location":"tutorials/prepare_dataset/","title":"Dataset","text":"In\u00a0[1]: Copied! <pre>! wget https://github.com/snuailab/assets/raw/main/waffle/sample_dataset/mnist.zip\n</pre> ! wget https://github.com/snuailab/assets/raw/main/waffle/sample_dataset/mnist.zip <pre>--2023-05-03 11:30:31--  https://github.com/snuailab/assets/raw/main/waffle/sample_dataset/mnist.zip\nResolving github.com (github.com)... 20.200.245.247\nConnecting to github.com (github.com)|20.200.245.247|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/snuailab/assets/main/waffle/sample_dataset/mnist.zip [following]\n--2023-05-03 11:30:31--  https://raw.githubusercontent.com/snuailab/assets/main/waffle/sample_dataset/mnist.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 157823 (154K) [application/zip]\nSaving to: \u2018mnist.zip\u2019\n\nmnist.zip           100%[===================&gt;] 154.12K  --.-KB/s    in 0.02s   \n\n2023-05-03 11:30:32 (9.02 MB/s) - \u2018mnist.zip\u2019 saved [157823/157823]\n\n</pre> In\u00a0[2]: Copied! <pre>! unzip mnist.zip -d mnist\n</pre> ! unzip mnist.zip -d mnist <pre>Archive:  mnist.zip\n  inflating: mnist/coco.json         \n   creating: mnist/images/\n  inflating: mnist/images/1.png      \n  inflating: mnist/images/10.png     \n  inflating: mnist/images/100.png    \n  inflating: mnist/images/11.png     \n  inflating: mnist/images/12.png     \n  inflating: mnist/images/13.png     \n  inflating: mnist/images/14.png     \n  inflating: mnist/images/15.png     \n  inflating: mnist/images/16.png     \n  inflating: mnist/images/17.png     \n  inflating: mnist/images/18.png     \n  inflating: mnist/images/19.png     \n  inflating: mnist/images/2.png      \n  inflating: mnist/images/20.png     \n  inflating: mnist/images/21.png     \n  inflating: mnist/images/22.png     \n  inflating: mnist/images/23.png     \n  inflating: mnist/images/24.png     \n  inflating: mnist/images/25.png     \n  inflating: mnist/images/26.png     \n  inflating: mnist/images/27.png     \n  inflating: mnist/images/28.png     \n  inflating: mnist/images/29.png     \n  inflating: mnist/images/3.png      \n  inflating: mnist/images/30.png     \n  inflating: mnist/images/31.png     \n  inflating: mnist/images/32.png     \n  inflating: mnist/images/33.png     \n  inflating: mnist/images/34.png     \n  inflating: mnist/images/35.png     \n  inflating: mnist/images/36.png     \n  inflating: mnist/images/37.png     \n  inflating: mnist/images/38.png     \n  inflating: mnist/images/39.png     \n  inflating: mnist/images/4.png      \n  inflating: mnist/images/40.png     \n  inflating: mnist/images/41.png     \n  inflating: mnist/images/42.png     \n  inflating: mnist/images/43.png     \n  inflating: mnist/images/44.png     \n  inflating: mnist/images/45.png     \n  inflating: mnist/images/46.png     \n  inflating: mnist/images/47.png     \n  inflating: mnist/images/48.png     \n  inflating: mnist/images/49.png     \n  inflating: mnist/images/5.png      \n  inflating: mnist/images/50.png     \n  inflating: mnist/images/51.png     \n  inflating: mnist/images/52.png     \n  inflating: mnist/images/53.png     \n  inflating: mnist/images/54.png     \n  inflating: mnist/images/55.png     \n  inflating: mnist/images/56.png     \n  inflating: mnist/images/57.png     \n  inflating: mnist/images/58.png     \n  inflating: mnist/images/59.png     \n  inflating: mnist/images/6.png      \n  inflating: mnist/images/60.png     \n  inflating: mnist/images/61.png     \n  inflating: mnist/images/62.png     \n  inflating: mnist/images/63.png     \n  inflating: mnist/images/64.png     \n  inflating: mnist/images/65.png     \n  inflating: mnist/images/66.png     \n  inflating: mnist/images/67.png     \n  inflating: mnist/images/68.png     \n  inflating: mnist/images/69.png     \n  inflating: mnist/images/7.png      \n  inflating: mnist/images/70.png     \n  inflating: mnist/images/71.png     \n  inflating: mnist/images/72.png     \n  inflating: mnist/images/73.png     \n  inflating: mnist/images/74.png     \n  inflating: mnist/images/75.png     \n  inflating: mnist/images/76.png     \n  inflating: mnist/images/77.png     \n  inflating: mnist/images/78.png     \n  inflating: mnist/images/79.png     \n  inflating: mnist/images/8.png      \n  inflating: mnist/images/80.png     \n  inflating: mnist/images/81.png     \n  inflating: mnist/images/82.png     \n  inflating: mnist/images/83.png     \n  inflating: mnist/images/84.png     \n  inflating: mnist/images/85.png     \n  inflating: mnist/images/86.png     \n  inflating: mnist/images/87.png     \n  inflating: mnist/images/88.png     \n  inflating: mnist/images/89.png     \n  inflating: mnist/images/9.png      \n  inflating: mnist/images/90.png     \n  inflating: mnist/images/91.png     \n  inflating: mnist/images/92.png     \n  inflating: mnist/images/93.png     \n  inflating: mnist/images/94.png     \n  inflating: mnist/images/95.png     \n  inflating: mnist/images/96.png     \n  inflating: mnist/images/97.png     \n  inflating: mnist/images/98.png     \n  inflating: mnist/images/99.png     \n  inflating: mnist/test.json         \n  inflating: mnist/train.json        \n  inflating: mnist/val.json          \n</pre> In\u00a0[4]: Copied! <pre>from waffle_hub.dataset import Dataset\nfrom waffle_hub import TaskType\n\ndataset = Dataset.from_coco(\n    name='mnist_det',\n    task=TaskType.OBJECT_DETECTION,\n    coco_file=\"./mnist/coco.json\",\n    coco_root_dir=\"./mnist/images\",\n)\n</pre> from waffle_hub.dataset import Dataset from waffle_hub import TaskType  dataset = Dataset.from_coco(     name='mnist_det',     task=TaskType.OBJECT_DETECTION,     coco_file=\"./mnist/coco.json\",     coco_root_dir=\"./mnist/images\", ) <pre>loading annotations into memory...\nDone (t=0.00s)\ncreating index...\nindex created!\n</pre> <pre>1it [00:00, 17.83it/s]:   0%|          | 0/100 [00:00&lt;?, ?it/s]\nImporting coco dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 1643.59it/s]\n</pre> <p><code>Dataset</code> instance provides several useful properties and methods. See Dataset Documentation for more details.</p> In\u00a0[\u00a0]: Copied! <pre>dataset.category_names\n</pre> dataset.category_names Out[\u00a0]: <pre>['1', '2']</pre> In\u00a0[6]: Copied! <pre>dataset.split(\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1,\n)\nlist(dataset.set_dir.iterdir())\n</pre> dataset.split(     train_ratio=0.8,     val_ratio=0.1,     test_ratio=0.1, ) list(dataset.set_dir.iterdir()) Out[6]: <pre>[PosixPath('datasets/mnist_det/sets/test.json'),\n PosixPath('datasets/mnist_det/sets/val.json'),\n PosixPath('datasets/mnist_det/sets/train.json'),\n PosixPath('datasets/mnist_det/sets/unlabeled.json')]</pre> In\u00a0[7]: Copied! <pre>from waffle_hub import DataType\n\nexport_dir = dataset.export(DataType.YOLO)\nexport_dir\n</pre> from waffle_hub import DataType  export_dir = dataset.export(DataType.YOLO) export_dir Out[7]: <pre>'datasets/mnist_det/exports/YOLO'</pre> In\u00a0[8]: Copied! <pre>export_dir = dataset.export(DataType.HUGGINGFACE)\nexport_dir\n</pre> export_dir = dataset.export(DataType.HUGGINGFACE) export_dir <pre>Downloading and preparing dataset generator/default to /home/lhj/.cache/huggingface/datasets/generator/default-f529974887995952/0.0.0...\n</pre> <pre>                                                              \r</pre> <pre>Dataset generator downloaded and prepared to /home/lhj/.cache/huggingface/datasets/generator/default-f529974887995952/0.0.0. Subsequent calls will reuse this data.\nDownloading and preparing dataset generator/default to /home/lhj/.cache/huggingface/datasets/generator/default-0e082ffb6d530bbe/0.0.0...\n</pre> <pre>                                                        \r</pre> <pre>Dataset generator downloaded and prepared to /home/lhj/.cache/huggingface/datasets/generator/default-0e082ffb6d530bbe/0.0.0. Subsequent calls will reuse this data.\nDownloading and preparing dataset generator/default to /home/lhj/.cache/huggingface/datasets/generator/default-f67a2a27d69a518b/0.0.0...\n</pre> <pre>                                                        \r</pre> <pre>Dataset generator downloaded and prepared to /home/lhj/.cache/huggingface/datasets/generator/default-f67a2a27d69a518b/0.0.0. Subsequent calls will reuse this data.\n</pre> <pre>                                                                                          \r</pre> Out[8]: <pre>'datasets/mnist_det/exports/HUGGINGFACE'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/prepare_dataset/#download-sample-dataset","title":"Download Sample dataset\u00b6","text":"<p>We provide sample dataset for this tutorial. You can download it from asset.  This dataset can be used for <code>Classification</code>, <code>Object Detection</code>, <code>Semantic Segmentation</code>, <code>Instance Segmentation</code> tasks.</p>"},{"location":"tutorials/prepare_dataset/#convert-to-waffle-dataset","title":"Convert to Waffle Dataset\u00b6","text":"<p>You can create <code>Waffle Dataset</code> from <code>COCO</code>, <code>YOLO</code>, <code>HuggingFace</code> format.</p>"},{"location":"tutorials/prepare_dataset/#split-dataset","title":"Split Dataset\u00b6","text":""},{"location":"tutorials/prepare_dataset/#export-dataset-to-other-formats","title":"Export Dataset to other formats\u00b6","text":"<p>After splitting dataset, you can export dataset to other formats.  The returned value of <code>Dataset.export()</code> can be used in training <code>Hub</code> directly.</p>"},{"location":"tutorials/using_hub/","title":"Using Hub","text":"In\u00a0[\u00a0]: Copied! <pre>from waffle_hub.hub.adapter.ultralytics import UltralyticsHub\nfrom waffle_hub import TaskType\n</pre> from waffle_hub.hub.adapter.ultralytics import UltralyticsHub from waffle_hub import TaskType <p>See what tasks, models are available in UltralyticsHub.</p> In\u00a0[2]: Copied! <pre>UltralyticsHub.MODEL_TYPES\n</pre> UltralyticsHub.MODEL_TYPES Out[2]: <pre>{'object_detection': {'yolov8': ['n', 's', 'm', 'l', 'x']},\n 'classification': {'yolov8': ['n', 's', 'm', 'l', 'x']},\n 'instance_segmentation': {'yolov8': ['n', 's', 'm', 'l', 'x']}}</pre> <p>By calling <code>UltralyticsHub.new()</code> method you can simply create an Ultralytics instance.</p> In\u00a0[3]: Copied! <pre>ultralytics_hub = UltralyticsHub.new(\n    name=\"ultralytics_mnist_detection\",\n    task=TaskType.OBJECT_DETECTION,\n    model_type=\"yolov8\",\n    model_size=\"n\",\n    categories=[\"1\", \"2\"]\n)\n</pre> ultralytics_hub = UltralyticsHub.new(     name=\"ultralytics_mnist_detection\",     task=TaskType.OBJECT_DETECTION,     model_type=\"yolov8\",     model_size=\"n\",     categories=[\"1\", \"2\"] ) <p><code>Hub</code> instance provides several useful properties and methods. See Hub Documentation for more details.</p> In\u00a0[4]: Copied! <pre>ultralytics_hub.categories\n</pre> ultralytics_hub.categories Out[4]: <pre>[{'supercategory': 'object', 'name': '1'},\n {'supercategory': 'object', 'name': '2'}]</pre> In\u00a0[5]: Copied! <pre>from waffle_hub.hub.adapter.hugging_face import HuggingFaceHub\nfrom waffle_hub import TaskType\n</pre> from waffle_hub.hub.adapter.hugging_face import HuggingFaceHub from waffle_hub import TaskType <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:56: UserWarning: \n                transformers 4.28.1 has not been tested.\n                We recommend you to use one of ['4.27.4']\n                \n  warnings.warn(\n</pre> In\u00a0[6]: Copied! <pre>HuggingFaceHub.MODEL_TYPES\n</pre> HuggingFaceHub.MODEL_TYPES Out[6]: <pre>{'object_detection': {'DETA': {'base': 'jozhang97/deta-resnet-50'},\n  'DETR': {'base': 'facebook/detr-resnet-50',\n   'large': 'facebook/detr-resnet-101'},\n  'YOLOS': {'tiny': 'hustvl/yolos-tiny'}},\n 'classification': {'ViT': {'tiny': 'WinKawaks/vit-tiny-patch16-224',\n   'base': 'google/vit-base-patch16-224'}}}</pre> In\u00a0[7]: Copied! <pre>huggingface_hub = HuggingFaceHub.new(\n    name=\"huggingface_mnist_detection\",\n    task=TaskType.OBJECT_DETECTION,\n    model_type=\"DETR\",\n    model_size=\"base\",\n    categories=[\"1\", \"2\"]\n)\n</pre> huggingface_hub = HuggingFaceHub.new(     name=\"huggingface_mnist_detection\",     task=TaskType.OBJECT_DETECTION,     model_type=\"DETR\",     model_size=\"base\",     categories=[\"1\", \"2\"] ) In\u00a0[8]: Copied! <pre>from waffle_hub.hub.adapter.tx_model import TxModelHub\nfrom waffle_hub import TaskType\n</pre> from waffle_hub.hub.adapter.tx_model import TxModelHub from waffle_hub import TaskType In\u00a0[9]: Copied! <pre>TxModelHub.MODEL_TYPES\n</pre> TxModelHub.MODEL_TYPES Out[9]: <pre>{'object_detection': {'YOLOv5': ['s', 'm', 'l']},\n 'classification': {'Classifier': ['s', 'm', 'l']}}</pre> In\u00a0[10]: Copied! <pre>tx_model_hub = TxModelHub.new(\n    name=\"tx_model_mnist_detection\",\n    task=TaskType.OBJECT_DETECTION,\n    model_type=\"YOLOv5\",\n    model_size=\"s\",\n    categories=[\"1\", \"2\"]\n)\n</pre> tx_model_hub = TxModelHub.new(     name=\"tx_model_mnist_detection\",     task=TaskType.OBJECT_DETECTION,     model_type=\"YOLOv5\",     model_size=\"s\",     categories=[\"1\", \"2\"] ) In\u00a0[11]: Copied! <pre>from waffle_hub.dataset import Dataset\nfrom waffle_hub import DataType\n\ndataset = Dataset.load(\"mnist_det\")\n</pre> from waffle_hub.dataset import Dataset from waffle_hub import DataType  dataset = Dataset.load(\"mnist_det\") In\u00a0[\u00a0]: Copied! <pre>dataset_dir = dataset.export(DataType.YOLO)\ntrain_result = ultralytics_hub.train(\n    dataset_dir,\n    image_size=320,\n    epochs=50,\n    batch_size=16\n)\ntrain_result\n</pre> dataset_dir = dataset.export(DataType.YOLO) train_result = ultralytics_hub.train(     dataset_dir,     image_size=320,     epochs=50,     batch_size=16 ) train_result In\u00a0[13]: Copied! <pre>import torch\ntorch.use_deterministic_algorithms(False)\n</pre> import torch torch.use_deterministic_algorithms(False) In\u00a0[\u00a0]: Copied! <pre>dataset_dir = dataset.export(DataType.HUGGINGFACE)\ntrain_result = huggingface_hub.train(\n    dataset_dir,\n    image_size=320,\n    epochs=50,\n    batch_size=16\n)\ntrain_result\n</pre> dataset_dir = dataset.export(DataType.HUGGINGFACE) train_result = huggingface_hub.train(     dataset_dir,     image_size=320,     epochs=50,     batch_size=16 ) train_result In\u00a0[\u00a0]: Copied! <pre>dataset_dir = dataset.export(DataType.TX_MODEL)\ntrain_result = tx_model_hub.train(\n    dataset_dir,\n    image_size=320,\n    epochs=50,\n    batch_size=16,\n    pretrained_model=\"base_models/detectors/small/model.pth\"\n)\ntrain_result\n</pre> dataset_dir = dataset.export(DataType.TX_MODEL) train_result = tx_model_hub.train(     dataset_dir,     image_size=320,     epochs=50,     batch_size=16,     pretrained_model=\"base_models/detectors/small/model.pth\" ) train_result In\u00a0[16]: Copied! <pre>ultralytics_hub = UltralyticsHub.load(\"ultralytics_mnist_detection\")\nultralytics_hub.evaluate(\"mnist_det\", set_name=\"test\")\n</pre> ultralytics_hub = UltralyticsHub.load(\"ultralytics_mnist_detection\") ultralytics_hub.evaluate(\"mnist_det\", set_name=\"test\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 25.25it/s]\n</pre> Out[16]: <pre>EvaluateResult(metrics=[{'tag': 'mAP', 'value': 0.8066571950912476}])</pre> In\u00a0[17]: Copied! <pre>huggingface_hub = HuggingFaceHub.load(\"huggingface_mnist_detection\")\nhuggingface_hub.evaluate(\"mnist_det\", set_name=\"test\")\n</pre> huggingface_hub = HuggingFaceHub.load(\"huggingface_mnist_detection\") huggingface_hub.evaluate(\"mnist_det\", set_name=\"test\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 21.73it/s]\n</pre> Out[17]: <pre>EvaluateResult(metrics=[{'tag': 'mAP', 'value': 0.18526874482631683}])</pre> In\u00a0[25]: Copied! <pre>tx_model_hub = TxModelHub.load(\"tx_model_mnist_detection\")\ntx_model_hub.evaluate(\"mnist_det\", set_name=\"test\")\n</pre> tx_model_hub = TxModelHub.load(\"tx_model_mnist_detection\") tx_model_hub.evaluate(\"mnist_det\", set_name=\"test\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 25.43it/s]\n</pre> Out[25]: <pre>EvaluateResult(metrics=[{'tag': 'mAP', 'value': 0.1792079210281372}])</pre> In\u00a0[18]: Copied! <pre>import PIL.Image\n</pre> import PIL.Image In\u00a0[19]: Copied! <pre>ultralytics_hub = UltralyticsHub.load(\"ultralytics_mnist_detection\")\nultralytics_hub.inference(\"mnist/images\", draw=True)\nPIL.Image.open(ultralytics_hub.draw_dir / \"1.png\")\n</pre> ultralytics_hub = UltralyticsHub.load(\"ultralytics_mnist_detection\") ultralytics_hub.inference(\"mnist/images\", draw=True) PIL.Image.open(ultralytics_hub.draw_dir / \"1.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:00&lt;00:00, 54.73it/s]\n</pre> Out[19]: In\u00a0[20]: Copied! <pre>huggingface_hub = HuggingFaceHub.load(\"huggingface_mnist_detection\")\nhuggingface_hub.inference(\"mnist/images\", draw=True)\nPIL.Image.open(huggingface_hub.draw_dir / \"1.png\")\n</pre> huggingface_hub = HuggingFaceHub.load(\"huggingface_mnist_detection\") huggingface_hub.inference(\"mnist/images\", draw=True) PIL.Image.open(huggingface_hub.draw_dir / \"1.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:00&lt;00:00, 42.81it/s]\n</pre> Out[20]: In\u00a0[21]: Copied! <pre>tx_model_hub = TxModelHub.load(\"tx_model_mnist_detection\")\ntx_model_hub.inference(\"mnist/images\", draw=True)\nPIL.Image.open(tx_model_hub.draw_dir / \"1.png\")\n</pre> tx_model_hub = TxModelHub.load(\"tx_model_mnist_detection\") tx_model_hub.inference(\"mnist/images\", draw=True) PIL.Image.open(tx_model_hub.draw_dir / \"1.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:00&lt;00:00, 62.38it/s]\n</pre> Out[21]: In\u00a0[22]: Copied! <pre>ultralytics_hub.export()\n</pre> ultralytics_hub.export() <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/ultralytics/nn/modules.py:474: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  elif self.dynamic or self.shape != shape:\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/ultralytics/yolo/utils/tal.py:241: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n  for i, stride in enumerate(strides):\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::sub_ on block input: 'tensor.1'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n</pre> Out[22]: <pre>ExportResult(export_file=PosixPath('hubs/ultralytics_mnist_detection/weights/model.onnx'))</pre> In\u00a0[23]: Copied! <pre>huggingface_hub.export()\n</pre> huggingface_hub.export() <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/transformers/models/detr/modeling_detr.py:575: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if attn_weights.size() != (batch_size * self.num_heads, target_len, source_len):\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/transformers/models/detr/modeling_detr.py:582: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if attention_mask.size() != (batch_size, 1, target_len, source_len):\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/transformers/models/detr/modeling_detr.py:606: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if attn_output.size() != (batch_size * self.num_heads, target_len, self.head_dim):\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/transformers/models/detr/image_processing_detr.py:1567: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n  for s, l, b in zip(scores, labels, boxes):\n</pre> Out[23]: <pre>ExportResult(export_file=PosixPath('hubs/huggingface_mnist_detection/weights/model.onnx'))</pre> In\u00a0[26]: Copied! <pre>tx_model_hub.export(device=\"cpu\")\n</pre> tx_model_hub.export(device=\"cpu\") <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::sub_ on block input: 'tensor.1'. This changes graph semantics. (Triggered internally at ../torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n</pre> Out[26]: <pre>ExportResult(export_file=PosixPath('hubs/tx_model_mnist_detection/weights/model.onnx'))</pre> In\u00a0[27]: Copied! <pre>ultralytics_hub.benchmark(image_size=320, batch_size=16)\n</pre> ultralytics_hub.benchmark(image_size=320, batch_size=16) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 97.22it/s]\n</pre> Out[27]: <pre>{'inference_time': 1.0294418334960938,\n 'fps': 1554.2403154204742,\n 'image_size': [320, 320],\n 'batch_size': 16,\n 'precision': 'fp32',\n 'device': 'cuda:0',\n 'cpu_name': '13th Gen Intel(R) Core(TM) i9-13900KF',\n 'gpu_name': 'NVIDIA GeForce RTX 4090'}</pre> In\u00a0[28]: Copied! <pre>huggingface_hub.benchmark(image_size=320, batch_size=16)\n</pre> huggingface_hub.benchmark(image_size=320, batch_size=16) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:02&lt;00:00, 42.96it/s]\n</pre> Out[28]: <pre>{'inference_time': 2.328606128692627,\n 'fps': 687.1063252325563,\n 'image_size': [320, 320],\n 'batch_size': 16,\n 'precision': 'fp32',\n 'device': 'cuda:0',\n 'cpu_name': '13th Gen Intel(R) Core(TM) i9-13900KF',\n 'gpu_name': 'NVIDIA GeForce RTX 4090'}</pre> In\u00a0[29]: Copied! <pre>tx_model_hub.benchmark(image_size=320, batch_size=16)\n</pre> tx_model_hub.benchmark(image_size=320, batch_size=16) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 113.23it/s]\n</pre> Out[29]: <pre>{'inference_time': 0.8841898441314697,\n 'fps': 1809.5661362992278,\n 'image_size': [320, 320],\n 'batch_size': 16,\n 'precision': 'fp32',\n 'device': 'cuda:0',\n 'cpu_name': '13th Gen Intel(R) Core(TM) i9-13900KF',\n 'gpu_name': 'NVIDIA GeForce RTX 4090'}</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/using_hub/#hub","title":"Hub\u00b6","text":"<p>Hub provides same interface for several backends. Let see how it works.</p>"},{"location":"tutorials/using_hub/#create-ultralytics-hub","title":"Create Ultralytics Hub\u00b6","text":""},{"location":"tutorials/using_hub/#create-huggingface-hub","title":"Create Huggingface Hub\u00b6","text":"<p>As you did in Ultralytics Hub, you can create Huggingface Hub instance with exactly same way.</p>"},{"location":"tutorials/using_hub/#create-tx-model-hub","title":"Create Tx Model Hub\u00b6","text":"<p>Tx Model is a private deep learning framework of SNUAILAB. You can use it by asking our team!  You can also create Tx Model Hub instance with exactly same way.</p>"},{"location":"tutorials/using_hub/#train","title":"Train\u00b6","text":""},{"location":"tutorials/using_hub/#load-dataset","title":"Load Dataset\u00b6","text":""},{"location":"tutorials/using_hub/#ultralytics","title":"Ultralytics\u00b6","text":""},{"location":"tutorials/using_hub/#huggingface","title":"Huggingface\u00b6","text":""},{"location":"tutorials/using_hub/#tx-model","title":"Tx Model\u00b6","text":""},{"location":"tutorials/using_hub/#evaluate","title":"Evaluate\u00b6","text":""},{"location":"tutorials/using_hub/#inference","title":"Inference\u00b6","text":""},{"location":"tutorials/using_hub/#export-to-onnx","title":"Export to onnx\u00b6","text":""},{"location":"tutorials/using_hub/#benchmark","title":"Benchmark\u00b6","text":""},{"location":"tutorials/visualization/","title":"Visualization","text":"In\u00a0[1]: Copied! <pre>import cv2\nfrom matplotlib import pyplot as plt\n\ndef imshow(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.axis('off')\n</pre> import cv2 from matplotlib import pyplot as plt  def imshow(image_path):     image = cv2.imread(image_path)     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)     plt.imshow(image)     plt.axis('off')  In\u00a0[2]: Copied! <pre>imshow(\"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\")\n</pre> imshow(\"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\") In\u00a0[3]: Copied! <pre>imshow(\"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\")\n</pre> imshow(\"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\") <p>Load trained model</p> In\u00a0[4]: Copied! <pre>from waffle_hub.hub.adapter.ultralytics import UltralyticsHub\n\nultralytics_hub = UltralyticsHub.load(\"falldown_yolo\")\nultralytics_model = ultralytics_hub.get_model()\n</pre> from waffle_hub.hub.adapter.ultralytics import UltralyticsHub  ultralytics_hub = UltralyticsHub.load(\"falldown_yolo\") ultralytics_model = ultralytics_hub.get_model() <pre>/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:56: UserWarning: \n                ultralytics 8.0.91 has not been tested.\n                We recommend you to use one of ['8.0.87']\n                \n  warnings.warn(\n/home/lhj/anaconda3/envs/waffle/lib/python3.9/site-packages/waffle_hub/__init__.py:56: UserWarning: \n                transformers 4.28.1 has not been tested.\n                We recommend you to use one of ['4.27.4']\n                \n  warnings.warn(\n</pre> <p>Hub provides several convinient functions to use trained models.</p> In\u00a0[21]: Copied! <pre>import torch\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\ndef visualize_feature_maps(hub, image_path, target_layer):\n    model = hub.get_model()\n    load_image = hub.get_image_loader()\n    \n    image, image_info = load_image(image_path)\n    _, feature_maps = model.get_feature_maps(image.clone().unsqueeze(0), target_layer)\n\n    feature_map = list(feature_maps.values())[0]\n    feature_map = feature_map.squeeze().mean(dim=0).detach().numpy()\n\n    h, w = image.shape[1:]\n    feature_map = cv2.resize(feature_map, (w, h))\n\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    \n    axes[0].title.set_text(\"Input\")\n    axes[0].imshow(image.permute(1, 2, 0).detach().numpy())\n    axes[0].axis('off')\n    axes[1].title.set_text(f\"{hub.backend}: {target_layer}\")\n    axes[1].imshow(feature_map)\n    axes[1].axis('off')\n    plt.show()\n</pre> import torch import cv2 import numpy as np from matplotlib import pyplot as plt  def visualize_feature_maps(hub, image_path, target_layer):     model = hub.get_model()     load_image = hub.get_image_loader()          image, image_info = load_image(image_path)     _, feature_maps = model.get_feature_maps(image.clone().unsqueeze(0), target_layer)      feature_map = list(feature_maps.values())[0]     feature_map = feature_map.squeeze().mean(dim=0).detach().numpy()      h, w = image.shape[1:]     feature_map = cv2.resize(feature_map, (w, h))      fig, axes = plt.subplots(1, 2, figsize=(10, 5))          axes[0].title.set_text(\"Input\")     axes[0].imshow(image.permute(1, 2, 0).detach().numpy())     axes[0].axis('off')     axes[1].title.set_text(f\"{hub.backend}: {target_layer}\")     axes[1].imshow(feature_map)     axes[1].axis('off')     plt.show() In\u00a0[37]: Copied! <pre>ultralytics_layers = list(filter(lambda x: \".bn\" in x, ultralytics_model.get_layer_names()))\nultralytics_layers\n</pre> ultralytics_layers = list(filter(lambda x: \".bn\" in x, ultralytics_model.get_layer_names())) ultralytics_layers  Out[37]: <pre>['model.0.bn',\n 'model.1.bn',\n 'model.2.cv1.bn',\n 'model.2.cv2.bn',\n 'model.2.m.0.cv1.bn',\n 'model.2.m.0.cv2.bn',\n 'model.3.bn',\n 'model.4.cv1.bn',\n 'model.4.cv2.bn',\n 'model.4.m.0.cv1.bn',\n 'model.4.m.0.cv2.bn',\n 'model.4.m.1.cv1.bn',\n 'model.4.m.1.cv2.bn',\n 'model.5.bn',\n 'model.6.cv1.bn',\n 'model.6.cv2.bn',\n 'model.6.m.0.cv1.bn',\n 'model.6.m.0.cv2.bn',\n 'model.6.m.1.cv1.bn',\n 'model.6.m.1.cv2.bn',\n 'model.7.bn',\n 'model.8.cv1.bn',\n 'model.8.cv2.bn',\n 'model.8.m.0.cv1.bn',\n 'model.8.m.0.cv2.bn',\n 'model.9.conv.bn']</pre> In\u00a0[97]: Copied! <pre>visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.3.bn\")\n</pre> visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.3.bn\") In\u00a0[68]: Copied! <pre>visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.7.bn\")\n</pre> visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.7.bn\") In\u00a0[98]: Copied! <pre>visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.3.bn\")\n</pre> visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.3.bn\") In\u00a0[69]: Copied! <pre>visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.7.bn\")\n</pre> visualize_feature_maps(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.7.bn\") <p>Blend function for visualize GradCAM.</p> In\u00a0[61]: Copied! <pre>def blend(image, cam):\n\"\"\"blend image and cam (same size and normalized)\"\"\"\n    image = np.uint8(image.permute(1, 2, 0).detach().numpy() * 255)\n    cam = np.uint8(cam.detach().numpy().squeeze() * 255)\n\n    print(cam.shape)\n    cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n    cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)\n    return cv2.addWeighted(cam, 0.7, image, 0.3, 0)\n\ndef visualize_cam(hub, image_path, target_layer):\n    model = hub.get_model()\n    load_image = hub.get_image_loader()\n    \n    image, image_info = load_image(image_path)\n    cam = model.get_cam(image.clone().unsqueeze(0), target_layer)\n\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n    \n    axes[0].title.set_text(\"Input\")\n    axes[0].imshow(image.permute(1, 2, 0).detach().numpy())\n    axes[0].axis('off')\n    axes[1].title.set_text(f\"CAM {hub.backend}: {target_layer}\")\n    axes[1].imshow(blend(image, cam))\n    axes[1].axis('off')\n    plt.show()\n</pre> def blend(image, cam):     \"\"\"blend image and cam (same size and normalized)\"\"\"     image = np.uint8(image.permute(1, 2, 0).detach().numpy() * 255)     cam = np.uint8(cam.detach().numpy().squeeze() * 255)      print(cam.shape)     cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)     cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)     return cv2.addWeighted(cam, 0.7, image, 0.3, 0)  def visualize_cam(hub, image_path, target_layer):     model = hub.get_model()     load_image = hub.get_image_loader()          image, image_info = load_image(image_path)     cam = model.get_cam(image.clone().unsqueeze(0), target_layer)      fig, axes = plt.subplots(1, 2, figsize=(10, 5))          axes[0].title.set_text(\"Input\")     axes[0].imshow(image.permute(1, 2, 0).detach().numpy())     axes[0].axis('off')     axes[1].title.set_text(f\"CAM {hub.backend}: {target_layer}\")     axes[1].imshow(blend(image, cam))     axes[1].axis('off')     plt.show() In\u00a0[95]: Copied! <pre>visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.3.bn\")\n</pre> visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.3.bn\") <pre>(224, 224)\n</pre> In\u00a0[\u00a0]: Copied! <pre>visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.7.bn\")\n</pre> visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"model.7.bn\") <pre>(224, 224)\n</pre> In\u00a0[96]: Copied! <pre>visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.3.bn\")\n</pre> visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.3.bn\") <pre>(224, 224)\n</pre> In\u00a0[\u00a0]: Copied! <pre>visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.7.bn\")\n</pre> visualize_cam(ultralytics_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"model.7.bn\") <pre>(224, 224)\n</pre> In\u00a0[73]: Copied! <pre>from waffle_hub.hub.adapter.hugging_face import HuggingFaceHub\n\nhuggingface_hub = HuggingFaceHub.load(\"falldown_hf_ori\")\nhuggingface_model = huggingface_hub.get_model()\nhuggingface_model.get_layer_names()\n</pre> from waffle_hub.hub.adapter.hugging_face import HuggingFaceHub  huggingface_hub = HuggingFaceHub.load(\"falldown_hf_ori\") huggingface_model = huggingface_hub.get_model() huggingface_model.get_layer_names() Out[73]: <pre>['',\n 'vit',\n 'vit.embeddings',\n 'vit.embeddings.patch_embeddings',\n 'vit.embeddings.patch_embeddings.projection',\n 'vit.embeddings.dropout',\n 'vit.encoder',\n 'vit.encoder.layer',\n 'vit.encoder.layer.0',\n 'vit.encoder.layer.0.attention',\n 'vit.encoder.layer.0.attention.attention',\n 'vit.encoder.layer.0.attention.attention.query',\n 'vit.encoder.layer.0.attention.attention.key',\n 'vit.encoder.layer.0.attention.attention.value',\n 'vit.encoder.layer.0.attention.attention.dropout',\n 'vit.encoder.layer.0.attention.output',\n 'vit.encoder.layer.0.attention.output.dense',\n 'vit.encoder.layer.0.attention.output.dropout',\n 'vit.encoder.layer.0.intermediate',\n 'vit.encoder.layer.0.intermediate.dense',\n 'vit.encoder.layer.0.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.0.output',\n 'vit.encoder.layer.0.output.dense',\n 'vit.encoder.layer.0.output.dropout',\n 'vit.encoder.layer.0.layernorm_before',\n 'vit.encoder.layer.0.layernorm_after',\n 'vit.encoder.layer.1',\n 'vit.encoder.layer.1.attention',\n 'vit.encoder.layer.1.attention.attention',\n 'vit.encoder.layer.1.attention.attention.query',\n 'vit.encoder.layer.1.attention.attention.key',\n 'vit.encoder.layer.1.attention.attention.value',\n 'vit.encoder.layer.1.attention.attention.dropout',\n 'vit.encoder.layer.1.attention.output',\n 'vit.encoder.layer.1.attention.output.dense',\n 'vit.encoder.layer.1.attention.output.dropout',\n 'vit.encoder.layer.1.intermediate',\n 'vit.encoder.layer.1.intermediate.dense',\n 'vit.encoder.layer.1.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.1.output',\n 'vit.encoder.layer.1.output.dense',\n 'vit.encoder.layer.1.output.dropout',\n 'vit.encoder.layer.1.layernorm_before',\n 'vit.encoder.layer.1.layernorm_after',\n 'vit.encoder.layer.2',\n 'vit.encoder.layer.2.attention',\n 'vit.encoder.layer.2.attention.attention',\n 'vit.encoder.layer.2.attention.attention.query',\n 'vit.encoder.layer.2.attention.attention.key',\n 'vit.encoder.layer.2.attention.attention.value',\n 'vit.encoder.layer.2.attention.attention.dropout',\n 'vit.encoder.layer.2.attention.output',\n 'vit.encoder.layer.2.attention.output.dense',\n 'vit.encoder.layer.2.attention.output.dropout',\n 'vit.encoder.layer.2.intermediate',\n 'vit.encoder.layer.2.intermediate.dense',\n 'vit.encoder.layer.2.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.2.output',\n 'vit.encoder.layer.2.output.dense',\n 'vit.encoder.layer.2.output.dropout',\n 'vit.encoder.layer.2.layernorm_before',\n 'vit.encoder.layer.2.layernorm_after',\n 'vit.encoder.layer.3',\n 'vit.encoder.layer.3.attention',\n 'vit.encoder.layer.3.attention.attention',\n 'vit.encoder.layer.3.attention.attention.query',\n 'vit.encoder.layer.3.attention.attention.key',\n 'vit.encoder.layer.3.attention.attention.value',\n 'vit.encoder.layer.3.attention.attention.dropout',\n 'vit.encoder.layer.3.attention.output',\n 'vit.encoder.layer.3.attention.output.dense',\n 'vit.encoder.layer.3.attention.output.dropout',\n 'vit.encoder.layer.3.intermediate',\n 'vit.encoder.layer.3.intermediate.dense',\n 'vit.encoder.layer.3.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.3.output',\n 'vit.encoder.layer.3.output.dense',\n 'vit.encoder.layer.3.output.dropout',\n 'vit.encoder.layer.3.layernorm_before',\n 'vit.encoder.layer.3.layernorm_after',\n 'vit.encoder.layer.4',\n 'vit.encoder.layer.4.attention',\n 'vit.encoder.layer.4.attention.attention',\n 'vit.encoder.layer.4.attention.attention.query',\n 'vit.encoder.layer.4.attention.attention.key',\n 'vit.encoder.layer.4.attention.attention.value',\n 'vit.encoder.layer.4.attention.attention.dropout',\n 'vit.encoder.layer.4.attention.output',\n 'vit.encoder.layer.4.attention.output.dense',\n 'vit.encoder.layer.4.attention.output.dropout',\n 'vit.encoder.layer.4.intermediate',\n 'vit.encoder.layer.4.intermediate.dense',\n 'vit.encoder.layer.4.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.4.output',\n 'vit.encoder.layer.4.output.dense',\n 'vit.encoder.layer.4.output.dropout',\n 'vit.encoder.layer.4.layernorm_before',\n 'vit.encoder.layer.4.layernorm_after',\n 'vit.encoder.layer.5',\n 'vit.encoder.layer.5.attention',\n 'vit.encoder.layer.5.attention.attention',\n 'vit.encoder.layer.5.attention.attention.query',\n 'vit.encoder.layer.5.attention.attention.key',\n 'vit.encoder.layer.5.attention.attention.value',\n 'vit.encoder.layer.5.attention.attention.dropout',\n 'vit.encoder.layer.5.attention.output',\n 'vit.encoder.layer.5.attention.output.dense',\n 'vit.encoder.layer.5.attention.output.dropout',\n 'vit.encoder.layer.5.intermediate',\n 'vit.encoder.layer.5.intermediate.dense',\n 'vit.encoder.layer.5.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.5.output',\n 'vit.encoder.layer.5.output.dense',\n 'vit.encoder.layer.5.output.dropout',\n 'vit.encoder.layer.5.layernorm_before',\n 'vit.encoder.layer.5.layernorm_after',\n 'vit.encoder.layer.6',\n 'vit.encoder.layer.6.attention',\n 'vit.encoder.layer.6.attention.attention',\n 'vit.encoder.layer.6.attention.attention.query',\n 'vit.encoder.layer.6.attention.attention.key',\n 'vit.encoder.layer.6.attention.attention.value',\n 'vit.encoder.layer.6.attention.attention.dropout',\n 'vit.encoder.layer.6.attention.output',\n 'vit.encoder.layer.6.attention.output.dense',\n 'vit.encoder.layer.6.attention.output.dropout',\n 'vit.encoder.layer.6.intermediate',\n 'vit.encoder.layer.6.intermediate.dense',\n 'vit.encoder.layer.6.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.6.output',\n 'vit.encoder.layer.6.output.dense',\n 'vit.encoder.layer.6.output.dropout',\n 'vit.encoder.layer.6.layernorm_before',\n 'vit.encoder.layer.6.layernorm_after',\n 'vit.encoder.layer.7',\n 'vit.encoder.layer.7.attention',\n 'vit.encoder.layer.7.attention.attention',\n 'vit.encoder.layer.7.attention.attention.query',\n 'vit.encoder.layer.7.attention.attention.key',\n 'vit.encoder.layer.7.attention.attention.value',\n 'vit.encoder.layer.7.attention.attention.dropout',\n 'vit.encoder.layer.7.attention.output',\n 'vit.encoder.layer.7.attention.output.dense',\n 'vit.encoder.layer.7.attention.output.dropout',\n 'vit.encoder.layer.7.intermediate',\n 'vit.encoder.layer.7.intermediate.dense',\n 'vit.encoder.layer.7.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.7.output',\n 'vit.encoder.layer.7.output.dense',\n 'vit.encoder.layer.7.output.dropout',\n 'vit.encoder.layer.7.layernorm_before',\n 'vit.encoder.layer.7.layernorm_after',\n 'vit.encoder.layer.8',\n 'vit.encoder.layer.8.attention',\n 'vit.encoder.layer.8.attention.attention',\n 'vit.encoder.layer.8.attention.attention.query',\n 'vit.encoder.layer.8.attention.attention.key',\n 'vit.encoder.layer.8.attention.attention.value',\n 'vit.encoder.layer.8.attention.attention.dropout',\n 'vit.encoder.layer.8.attention.output',\n 'vit.encoder.layer.8.attention.output.dense',\n 'vit.encoder.layer.8.attention.output.dropout',\n 'vit.encoder.layer.8.intermediate',\n 'vit.encoder.layer.8.intermediate.dense',\n 'vit.encoder.layer.8.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.8.output',\n 'vit.encoder.layer.8.output.dense',\n 'vit.encoder.layer.8.output.dropout',\n 'vit.encoder.layer.8.layernorm_before',\n 'vit.encoder.layer.8.layernorm_after',\n 'vit.encoder.layer.9',\n 'vit.encoder.layer.9.attention',\n 'vit.encoder.layer.9.attention.attention',\n 'vit.encoder.layer.9.attention.attention.query',\n 'vit.encoder.layer.9.attention.attention.key',\n 'vit.encoder.layer.9.attention.attention.value',\n 'vit.encoder.layer.9.attention.attention.dropout',\n 'vit.encoder.layer.9.attention.output',\n 'vit.encoder.layer.9.attention.output.dense',\n 'vit.encoder.layer.9.attention.output.dropout',\n 'vit.encoder.layer.9.intermediate',\n 'vit.encoder.layer.9.intermediate.dense',\n 'vit.encoder.layer.9.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.9.output',\n 'vit.encoder.layer.9.output.dense',\n 'vit.encoder.layer.9.output.dropout',\n 'vit.encoder.layer.9.layernorm_before',\n 'vit.encoder.layer.9.layernorm_after',\n 'vit.encoder.layer.10',\n 'vit.encoder.layer.10.attention',\n 'vit.encoder.layer.10.attention.attention',\n 'vit.encoder.layer.10.attention.attention.query',\n 'vit.encoder.layer.10.attention.attention.key',\n 'vit.encoder.layer.10.attention.attention.value',\n 'vit.encoder.layer.10.attention.attention.dropout',\n 'vit.encoder.layer.10.attention.output',\n 'vit.encoder.layer.10.attention.output.dense',\n 'vit.encoder.layer.10.attention.output.dropout',\n 'vit.encoder.layer.10.intermediate',\n 'vit.encoder.layer.10.intermediate.dense',\n 'vit.encoder.layer.10.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.10.output',\n 'vit.encoder.layer.10.output.dense',\n 'vit.encoder.layer.10.output.dropout',\n 'vit.encoder.layer.10.layernorm_before',\n 'vit.encoder.layer.10.layernorm_after',\n 'vit.encoder.layer.11',\n 'vit.encoder.layer.11.attention',\n 'vit.encoder.layer.11.attention.attention',\n 'vit.encoder.layer.11.attention.attention.query',\n 'vit.encoder.layer.11.attention.attention.key',\n 'vit.encoder.layer.11.attention.attention.value',\n 'vit.encoder.layer.11.attention.attention.dropout',\n 'vit.encoder.layer.11.attention.output',\n 'vit.encoder.layer.11.attention.output.dense',\n 'vit.encoder.layer.11.attention.output.dropout',\n 'vit.encoder.layer.11.intermediate',\n 'vit.encoder.layer.11.intermediate.dense',\n 'vit.encoder.layer.11.intermediate.intermediate_act_fn',\n 'vit.encoder.layer.11.output',\n 'vit.encoder.layer.11.output.dense',\n 'vit.encoder.layer.11.output.dropout',\n 'vit.encoder.layer.11.layernorm_before',\n 'vit.encoder.layer.11.layernorm_after',\n 'vit.layernorm',\n 'classifier']</pre> In\u00a0[89]: Copied! <pre>visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"vit.encoder.layer.2.layernorm_after\")\n</pre> visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"vit.encoder.layer.2.layernorm_after\") <pre>(224, 224)\n</pre> In\u00a0[91]: Copied! <pre>visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"vit.encoder.layer.10.layernorm_after\")\n</pre> visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/falldown/23_1080_4000kbps/622_frame_4080.jpg\", \"vit.encoder.layer.10.layernorm_after\") <pre>(224, 224)\n</pre> In\u00a0[90]: Copied! <pre>visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"vit.encoder.layer.2.layernorm_after\")\n</pre> visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"vit.encoder.layer.2.layernorm_after\") <pre>(224, 224)\n</pre> In\u00a0[92]: Copied! <pre>visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"vit.encoder.layer.10.layernorm_after\")\n</pre> visualize_cam(huggingface_hub, \"datasets/falldown/exports/YOLO/test/none/22_1080_4000kbps/256_frame_5250.jpg\", \"vit.encoder.layer.10.layernorm_after\") <pre>(224, 224)\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/visualization/#visualization-in-deep-learning","title":"Visualization in Deep Learning\u00b6","text":"<p>Visualization is a powerful tool for understanding and interpreting machine learning models. There are many different ways to visualize models, including visualizing the learned features, visualizing the activations, and visualizing the output of intermediate layers. </p> <p>In this tutorial, we will cover the following topics: </p> <ol> <li>Load trained model from Hub</li> <li>Visualizing the learned features with Hub</li> <li>Visualizing the class activation with Hub</li> </ol>"},{"location":"tutorials/visualization/#load-trained-model-from-hub","title":"Load trained model from Hub\u00b6","text":"<p>In this tutorial, we'll use our custom <code>Safety Dataset</code> that contains two classes: <code>Falldown</code> and <code>NotFalldown</code>. </p>"},{"location":"tutorials/visualization/#visualizing-the-learned-features-with-hub","title":"Visualizing the learned features with Hub\u00b6","text":""},{"location":"tutorials/visualization/#visualizing-the-class-activation-with-hub","title":"Visualizing the class activation with Hub\u00b6","text":""},{"location":"tutorials/visualization/#gradcam-with-ultralytics-hub","title":"GradCAM with Ultralytics Hub\u00b6","text":""},{"location":"tutorials/visualization/#gradcam-with-huggingface-hub","title":"GradCAM with Huggingface Hub\u00b6","text":"<p>We also trained ViT-base model via Huggingface Hub.</p>"},{"location":"waffle_hub/","title":"Waffle Hub","text":"<p><code>Waffle Hub</code> provide two key component classes: <code>Hub</code> and <code>Dataset</code>.</p>"},{"location":"waffle_hub/#hub","title":"Hub","text":"<p><code>Hub</code> provides same interface for various powerfull Deep Learning Frameworks. Here is our brief system architecture.</p> <p></p> <p>Each input and output adapter is responsible for converting our interface to the framework's interface. For example, <code>Ultralytics</code> uses <code>imgsz</code> for image size parameter, but <code>detectron2</code> uses <code>IMAGE_SIZE</code>. So, we need to convert our interface to the framework's interface. <code>waffle_hub</code> provides <code>InputAdapter</code> and <code>OutputAdapter</code> for this purpose.</p>"},{"location":"waffle_hub/#dataset","title":"Dataset","text":"<p><code>Dataset</code> class support many types of data format such as <code>coco</code>, <code>yolo</code>. You can use it to convert dataset or manage dataset.</p>"},{"location":"waffle_hub/dataset/dataset/","title":"Dataset","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.add_annotations","title":"<code>add_annotations(annotations)</code>","text":"<p>Add \"Annotation\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>list[Annotation]</code> <p>list of \"Annotation\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.add_categories","title":"<code>add_categories(categories)</code>","text":"<p>Add \"Category\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>categories</code> <code>list[Category]</code> <p>list of \"Category\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.add_images","title":"<code>add_images(images)</code>","text":"<p>Add \"Image\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>list[Image]</code> <p>list of \"Image\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.add_predictions","title":"<code>add_predictions(predictions)</code>","text":"<p>Add \"Annotation\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>list[Annotation]</code> <p>list of \"Annotation\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.clone","title":"<code>clone(src_name, name, src_root_dir=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Clone Existing Dataset. This method clones an existing dataset.</p> <p>Parameters:</p> Name Type Description Default <code>src_name</code> <code>str</code> <p>Dataset name to clone. It should be Waffle Created Dataset.</p> required <code>name</code> <code>str</code> <p>New Dataset name</p> required <code>src_root_dir</code> <code>str</code> <p>Source Dataset root directory. Defaults to None.</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>New Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if source dataset does not exist.</p> <code>FileExistsError</code> <p>if new dataset name already exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.clone(\"my_dataset\", \"my_dataset_clone\")\n&gt;&gt;&gt; ds.name\n'my_dataset_clone'  # cloned dataset name\n&gt;&gt;&gt; ds.task\n'CLASSIFICATION'   # original dataset task\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.delete","title":"<code>delete()</code>","text":"<p>Delete Dataset</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.export","title":"<code>export(data_type)</code>","text":"<p>Export Dataset to Specific data formats</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>Union[str, DataType]</code> <p>export data type. one of [\"YOLO\", \"COCO\"].</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if data_type is not one of DataType.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset.load(\"some_dataset\")\n&gt;&gt;&gt; dataset.export(data_type=\"YOLO\")\npath/to/dataset_dir/exports/yolo\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.export--you-can-train-with-exported-dataset","title":"You can train with exported dataset","text":"<pre><code>&gt;&gt;&gt; hub.train(\"path/to/dataset_dir/exports/yolo\", ...)\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>exported dataset directory</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_coco","title":"<code>from_coco(name, task, coco_file, coco_root_dir, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from coco format. This method imports coco format dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Dataset task.</p> required <code>coco_file</code> <code>Union[str, list[str]]</code> <p>Coco json file path. If given list, it will be regarded as [train, val, test] json file.</p> required <code>coco_root_dir</code> <code>Union[str, list[str]]</code> <p>Coco image root directory. If given list, it will be regarded as [train, val, test] coco root file.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if new dataset name already exist.</p> <p>Examples:</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_coco--import-one-coco-json-file","title":"Import one coco json file.","text":"<pre><code>&gt;&gt;&gt; ds = Dataset.from_coco(\"my_dataset\", \"object_detection\", \"path/to/coco.json\", \"path/to/coco_root\")\n&gt;&gt;&gt; ds.images\n{1: &lt;Image: 1&gt;, 2: &lt;Image: 2&gt;, 3: &lt;Image: 3&gt;, 4: &lt;Image: 4&gt;, 5: &lt;Image: 5&gt;}\n&gt;&gt;&gt; ds.annotations\n{1: &lt;Annotation: 1&gt;, 2: &lt;Annotation: 2&gt;, 3: &lt;Annotation: 3&gt;, 4: &lt;Annotation: 4&gt;, 5: &lt;Annotation: 5&gt;}\n&gt;&gt;&gt; ds.categories\n{1: &lt;Category: 1&gt;, 2: &lt;Category: 2&gt;, 3: &lt;Category: 3&gt;, 4: &lt;Category: 4&gt;, 5: &lt;Category: 5&gt;}\n&gt;&gt;&gt; ds.category_names\n['person', 'bicycle', 'car', 'motorcycle', 'airplane']\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_coco--import-multiple-coco-json-files","title":"Import multiple coco json files.","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_coco--you-can-give-coco_file-as-list","title":"You can give coco_file as list.","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_coco--given-coco-files-are-regarded-as-train-val-test-json-files","title":"Given coco files are regarded as [train, [val, [test]]] json files.","text":"<pre><code>&gt;&gt;&gt; ds = Dataset.from_coco(\"my_dataset\", \"object_detection\", [\"coco_train.json\", \"coco_val.json\"], [\"coco_train_root\", \"coco_val_root\"])\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_huggingface","title":"<code>from_huggingface(name, task, dataset_dir, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from huggingface datasets. This method imports huggingface dataset from directory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>dataset_dir</code> <code>str</code> <p>Hugging Face dataset directory.</p> required <code>task</code> <code>str</code> <p>Task name.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if dataset name already exists</p> <code>ValueError</code> <p>if dataset is not Dataset or DatasetDict</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.from_huggingface(\"huggingface\", \"object_detection\", \"path/to/huggingface/dataset\")\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.from_yolo","title":"<code>from_yolo(name, task, yaml_path, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from yolo format. This method imports dataset from yolo(ultralytics) yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Dataset task.</p> required <code>yaml_path</code> <code>str</code> <p>Yolo yaml file path.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> Example <p>ds = Dataset.from_yolo(\"yolo\", \"classification\", \"path/to/yolo.yaml\")</p> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Imported dataset.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.get_annotations","title":"<code>get_annotations(image_id=None)</code>","text":"<p>Get \"Annotation\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>int</code> <p>image id. None for all \"Annotation\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Annotation]</code> <p>list[Annotation]: \"Annotation\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.get_categories","title":"<code>get_categories(category_ids=None)</code>","text":"<p>Get \"Category\"s.</p> <p>Parameters:</p> Name Type Description Default <code>category_ids</code> <code>list[int]</code> <p>id list. None for all \"Category\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Category]</code> <p>list[Category]: \"Category\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.get_images","title":"<code>get_images(image_ids=None, labeled=True)</code>","text":"<p>Get \"Image\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_ids</code> <code>list[int]</code> <p>id list. None for all \"Image\"s. Defaults to None.</p> <code>None</code> <code>labeled</code> <code>bool</code> <p>get labeled images. False for unlabeled images. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Image]</code> <p>list[Image]: \"Image\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.get_predictions","title":"<code>get_predictions(image_id=None)</code>","text":"<p>Get \"Prediction\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>int</code> <p>image id. None for all \"Prediction\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Annotation]</code> <p>list[Annotation]: \"Prediction\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.get_split_ids","title":"<code>get_split_ids()</code>","text":"<p>Get split ids</p> <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>list[list[int]]: split ids</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.initialize","title":"<code>initialize()</code>","text":"<p>Initialize Dataset. It creates necessary directories under {dataset_root_dir}/{dataset_name}.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.initialized","title":"<code>initialized()</code>","text":"<p>Check if Dataset has been initialized or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>initialized -&gt; True not initialized -&gt; False</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.load","title":"<code>load(name, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Load Dataset. This method loads an existing dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name that Waffle Created</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if source dataset does not exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.load(\"my_dataset\")\n&gt;&gt;&gt; ds.name\n'my_dataset'  # dataset name\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.new","title":"<code>new(name, task, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Create New Dataset. This method creates a new dataset directory and initialize dataset info file. If you have other types of data, you can use from_* methods to create a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>task</code> <code>str</code> <p>Dataset task</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if dataset name already exists</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.new(\"my_dataset\", \"CLASSIFICATION\")\n&gt;&gt;&gt; ds.name\n'my_dataset'  # dataset name\n&gt;&gt;&gt; ds.task  # dataset task\n'CLASSIFICATION'\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.dataset.Dataset.split","title":"<code>split(train_ratio, val_ratio=0.0, test_ratio=0.0, seed=0)</code>","text":"<p>Split Dataset to train, validation, test, (unlabeled) sets.</p> <p>Parameters:</p> Name Type Description Default <code>train_ratio</code> <code>float</code> <p>train num ratio (0 ~ 1).</p> required <code>val_ratio</code> <code>float</code> <p>val num ratio (0 ~ 1).</p> <code>0.0</code> <code>test_ratio</code> <code>float</code> <p>test num ratio (0 ~ 1).</p> <code>0.0</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if train_ratio is not between 0.0 and 1.0.</p> <code>ValueError</code> <p>if train_ratio + val_ratio + test_ratio is not 1.0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset.load(\"some_dataset\")\n&gt;&gt;&gt; dataset.split(train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\n&gt;&gt;&gt; dataset.get_split_ids()\n[[1, 2, 3, 4, 5, 6, 7, 8], [9], [10], []]  # train, val, test, unlabeled image ids\n</code></pre>"},{"location":"waffle_hub/dataset/field/","title":"Field","text":""},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.Annotation","title":"<code>Annotation</code>","text":"<p>         Bases: <code>BaseField</code></p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.classification","title":"<code>classification(annotation_id=None, image_id=None, category_id=None, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Classification Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.instance_segmentation","title":"<code>instance_segmentation(annotation_id=None, image_id=None, category_id=None, bbox=None, segmentation=None, area=None, iscrowd=0, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Instance Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>bbox</code> <code>list[float]</code> <p>[x1, y1, w, h].</p> <code>None</code> <code>segmentation</code> <code>list[list[float]]</code> <p>[[x1, y1, x2, y2, x3, y3, ...], [polygon]].</p> <code>None</code> <code>area</code> <code>int</code> <p>segmentation segmentation area.</p> <code>None</code> <code>iscrowd</code> <code>int</code> <p>is crowd or not. Default to 0.</p> <code>0</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.keypoint_detection","title":"<code>keypoint_detection(annotation_id=None, image_id=None, category_id=None, bbox=None, keypoints=None, num_keypoints=None, area=None, segmentation=None, iscrowd=0, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Keypoint Detection Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>bbox</code> <code>list[float]</code> <p>[x1, y1, w, h].</p> <code>None</code> <code>keypoints</code> <code>list[float]</code> <p>[x1, y1, v1(visible flag), x2, y2, v2(visible flag), ...]. visible flag is one of [0(Not labeled), 1(Labeled but not visible), 2(labeled and visible)]</p> <code>None</code> <code>num_keypoints</code> <code>int</code> <p>number of labeled keypoints</p> <code>None</code> <code>area</code> <code>int</code> <p>segmentation segmentation or bbox area.</p> <code>None</code> <code>segmentation</code> <code>list[list[float]]</code> <p>[[x1, y1, x2, y2, x3, y3, ...], [polygon]].</p> <code>None</code> <code>iscrowd</code> <code>int</code> <p>is crowd or not. Default to 0.</p> <code>0</code> <code>score</code> <code>list[float]</code> <p>prediction scores. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.new","title":"<code>new(annotation_id=None, image_id=None, category_id=None, bbox=None, segmentation=None, area=None, keypoints=None, num_keypoints=None, caption=None, value=None, iscrowd=None, score=None, task=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>bbox</code> <code>list[float]</code> <p>[x1, y1, w, h].</p> <code>None</code> <code>segmentation</code> <code>list[list[float]]</code> <p>[[[x1, y1, x2, y2, x3, y3, ...], [...]].</p> <code>None</code> <code>area</code> <code>int</code> <p>bbox area.</p> <code>None</code> <code>keypoints</code> <code>list[float]</code> <p>[x1, y1, v1(visible flag), x2, y2, v2(visible flag), ...]. visible flag is one of [0(Not labeled), 1(Labeled but not visible), 2(labeled and visible)]</p> <code>None</code> <code>num_keypoints</code> <code>int</code> <p>number of labeled keypoints</p> <code>None</code> <code>caption</code> <code>str</code> <p>string.</p> <code>None</code> <code>value</code> <code>float</code> <p>regression value.</p> <code>None</code> <code>iscrowd</code> <code>int</code> <p>is crowd or not. Default to None.</p> <code>None</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <code>task</code> <code>Union[str, TaskType]</code> <p>task type. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.object_detection","title":"<code>object_detection(annotation_id=None, image_id=None, category_id=None, bbox=None, area=None, iscrowd=0, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Object Detection Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>bbox</code> <code>list[float]</code> <p>[x1, y1, w, h].</p> <code>None</code> <code>area</code> <code>int</code> <p>bbox area.</p> <code>None</code> <code>iscrowd</code> <code>int</code> <p>is crowd or not. Default to 0.</p> <code>0</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.regression","title":"<code>regression(annotation_id=None, image_id=None, value=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Regression Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>value</code> <code>float</code> <p>regression value.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.semantic_segmentation","title":"<code>semantic_segmentation(annotation_id=None, image_id=None, category_id=None, bbox=None, segmentation=None, area=None, iscrowd=0, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Segmentation Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> <code>None</code> <code>bbox</code> <code>list[float]</code> <p>[x1, y1, w, h].</p> <code>None</code> <code>segmentation</code> <code>list[list[float]]</code> <p>[[x1, y1, x2, y2, x3, y3, ...], [polygon]].</p> <code>None</code> <code>area</code> <code>int</code> <p>segmentation segmentation area.</p> <code>None</code> <code>iscrowd</code> <code>int</code> <p>is crowd or not. Default to 0.</p> <code>0</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.text_recognition","title":"<code>text_recognition(annotation_id=None, image_id=None, caption=None, score=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Text Recognition Annotation Format</p> <p>Parameters:</p> Name Type Description Default <code>annotation_id</code> <code>int</code> <p>annotaion id. natural number.</p> <code>None</code> <code>image_id</code> <code>int</code> <p>image id. natural number.</p> <code>None</code> <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>caption</code> <code>str</code> <p>string.</p> <code>None</code> <code>score</code> <code>float</code> <p>prediction score. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Annotation</code> <code>Annotation</code> <p>annotation class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.annotation.Annotation.to_dict","title":"<code>to_dict()</code>","text":"<p>Get Dictionary of Annotation Data</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>annotation dictionary.</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.Category","title":"<code>Category</code>","text":"<p>         Bases: <code>BaseField</code></p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.classification","title":"<code>classification(category_id, name, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Classification Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.instance_segmentation","title":"<code>instance_segmentation(category_id, name, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Instance Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.keypoint_detection","title":"<code>keypoint_detection(category_id, name, keypoints, skeleton, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Keypoint Detection Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>keypoints</code> <code>list[str]</code> <p>category name.</p> required <code>skeleton</code> <code>list[list[int]]</code> <p>skeleton edges.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.new","title":"<code>new(category_id, name, supercategory=None, keypoints=None, skeleton=None, task=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <code>keypoints</code> <code>list[str]</code> <p>category name.</p> <code>None</code> <code>skeleton</code> <code>list[list[int]]</code> <p>skeleton edges.</p> <code>None</code> <code>task</code> <code>Union[str, TaskType]</code> <p>task type. Default to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.object_detection","title":"<code>object_detection(category_id, name, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Object Detection Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.semantic_segmentation","title":"<code>semantic_segmentation(category_id, name, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Segmentation Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.text_recognition","title":"<code>text_recognition(category_id, name, supercategory=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Text Recognition Category Format</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>category id. natural number.</p> required <code>name</code> <code>str</code> <p>category name.</p> required <code>supercategory</code> <code>str</code> <p>supercategory name.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Category</code> <code>Category</code> <p>category class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.category.Category.to_dict","title":"<code>to_dict()</code>","text":"<p>Get Dictionary of Category</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>annotation dictionary.</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.Image","title":"<code>Image</code>","text":"<p>         Bases: <code>BaseField</code></p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.image.Image.new","title":"<code>new(image_id, file_name, width, height, date_captured=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Image Format</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>int</code> <p>image id. natural number.</p> required <code>file_name</code> <code>str</code> <p>file name. relative file path.</p> required <code>width</code> <code>int</code> <p>image width.</p> required <code>height</code> <code>int</code> <p>image height.</p> required <code>date_captured</code> <code>str</code> <p>date_captured string. \"%Y-%m-%d %H:%M:%S\"</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Image</code> <code>Image</code> <p>image class</p>"},{"location":"waffle_hub/dataset/field/#waffle_hub.schema.fields.image.Image.to_dict","title":"<code>to_dict()</code>","text":"<p>Get Dictionary of Category</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>annotation dictionary.</p>"},{"location":"waffle_hub/hub/hub/","title":"Hub","text":"<p>         Bases: <code>BaseHub</code></p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.adapter.ultralytics.ultralytics_hub.UltralyticsHub.new","title":"<code>new(name, task=None, model_type=None, model_size=None, categories=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Create Ultralytics Hub.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Hub name</p> required <code>task</code> <code>str</code> <p>Task Name. See UltralyticsHub.TASKS. Defaults to None.</p> <code>None</code> <code>model_type</code> <code>str</code> <p>Model Type. See UltralyticsHub.MODEL_TYPES. Defaults to None.</p> <code>None</code> <code>model_size</code> <code>str</code> <p>Model Size. See UltralyticsHub.MODEL_SIZES. Defaults to None.</p> <code>None</code> <code>categories</code> <code>Union[list[dict], list]</code> <p>class dictionary or list. [{\"supercategory\": \"name\"}, ] or [\"name\",].</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>Root directory of hub repository. Defaults to None.</p> <code>None</code>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.artifact_dir","title":"<code>artifact_dir: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Artifact Directory. This is raw output of each backend.</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.backend","title":"<code>backend: str</code>  <code>writable</code> <code>property</code>","text":"<p>Backend name</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.best_ckpt_file","title":"<code>best_ckpt_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Best Checkpoint File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.draw_dir","title":"<code>draw_dir: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Draw Results Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.evaluate_file","title":"<code>evaluate_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Evaluate Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.hub_dir","title":"<code>hub_dir: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Hub(Model) Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.inference_dir","title":"<code>inference_dir: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Inference Results Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.inference_file","title":"<code>inference_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Inference Results File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.last_ckpt_file","title":"<code>last_ckpt_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Last Checkpoint File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.metric_file","title":"<code>metric_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Metric Csv File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.model_config_file","title":"<code>model_config_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Model Config yaml File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.model_size","title":"<code>model_size: str</code>  <code>writable</code> <code>property</code>","text":"<p>Model Size</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.model_type","title":"<code>model_type: str</code>  <code>writable</code> <code>property</code>","text":"<p>Model Type</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.name","title":"<code>name: str</code>  <code>writable</code> <code>property</code>","text":"<p>Hub name</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.onnx_file","title":"<code>onnx_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Best Checkpoint File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.root_dir","title":"<code>root_dir: Path</code>  <code>writable</code> <code>property</code>","text":"<p>Root Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.task","title":"<code>task: str</code>  <code>writable</code> <code>property</code>","text":"<p>Task Name</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.train_config_file","title":"<code>train_config_file: Path</code>  <code>property</code> <code>cached</code>","text":"<p>Train Config yaml File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.version","title":"<code>version: str</code>  <code>writable</code> <code>property</code>","text":"<p>Version</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.benchmark","title":"<code>benchmark(image_size=None, batch_size=16, device='0', half=False, trial=100)</code>","text":"<p>Benchmark Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>inference image size. None for same with train_config (recommended).</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>trial</code> <code>int</code> <p>number of trials. Defaults to 100.</p> <code>100</code> Example <p>hub.benchmark(         image_size=640,         batch_size=16,         device=\"0\",         half=False,         trial=100,     ) {     \"inference_time\": 0.123,     \"fps\": 123.123,     \"image_size\": [640, 640],     \"batch_size\": 16,     \"device\": \"0\",     \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",     \"gpu_name\": \"GeForce GTX 1080 Ti\", }</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>benchmark result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.check_train_sanity","title":"<code>check_train_sanity()</code>","text":"<p>Check if all essential files are exist.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all files are exist else False</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.delete_artifact","title":"<code>delete_artifact()</code>","text":"<p>Delete Artifact Directory. It can be trained again.</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.evaluate","title":"<code>evaluate(dataset_name, set_name='test', batch_size=4, image_size=None, letter_box=None, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0', draw=False, dataset_root_dir=None, hold=True)</code>","text":"<p>Start Evaluate</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>waffle dataset name.</p> required <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. Defaults to None.</p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. Defaults to \"0\".</p> <code>'0'</code> <code>draw</code> <code>bool</code> <p>draw. Defaults to False.</p> <code>False</code> <code>dataset_root_dir</code> <code>str</code> <p>dataset root dir. Defaults to None.</p> <code>None</code> <code>hold</code> <code>bool</code> <p>hold. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        dataset_name=\"detection_dataset\",\n        batch_size=4,\n        image_size=640,\n        letterbox=False,\n        confidence_threshold=0.25,\n        iou_threshold=0.5,\n        workers=4,\n        device=\"0\",\n    )\n# or you can use train option by passing None\n&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        ...\n        image_size=None,  # use train option\n        letterbox=None,  # use train option\n        ...\n    )\n&gt;&gt;&gt; evaluate_result.metrics\n[{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>EvaluateResult</code> <code>EvaluateResult</code> <p>evaluate result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.export","title":"<code>export(image_size=None, batch_size=16, opset_version=11, half=False, device='0', hold=True)</code>","text":"<p>Export Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>inference image size. None for same with train_config (recommended).</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>opset_version</code> <code>int</code> <p>onnx opset version. Defaults to 11.</p> <code>11</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>hold</code> <code>bool</code> <p>hold or not. If True then it holds until task finished. If False then return Inferece Callback and run in background. Defaults to True.</p> <code>True</code> Example <p>export_result = hub.export(     image_size=640,     batch_size=16,     opset_version=11, )</p> <p>Returns:</p> Name Type Description <code>ExportResult</code> <code>ExportResult</code> <p>export result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.export--or-simply-use-train-option-by-passing-none","title":"or simply use train option by passing None","text":"<p>export_result = hub.export(     ...,     image_size=None,  # use train option     ... ) export_result.export_file hubs/my_hub/weights/model.onnx</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.from_model_config","title":"<code>from_model_config(name, model_config_file, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Create new Hub with model config.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>hub name.</p> required <code>model_config_file</code> <code>str</code> <p>model config yaml file.</p> required <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Hub</code> <code>BaseHub</code> <p>New Hub instance</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.get_evaluate_result","title":"<code>get_evaluate_result()</code>","text":"<p>Get evaluate result from evaluate file.</p> Example <p>hub.get_evaluate_result() [     {         \"tag\": \"mAP\",         \"value\": 0.5,     }, ]</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>list[dict]</code> <p>evaluate result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.get_inference_result","title":"<code>get_inference_result()</code>","text":"<p>Get inference result from inference file.</p> Example <p>hub.get_inference_result() [     {         \"id\": \"00000001\",         \"category\": \"person\",         \"bbox\": [0.1, 0.2, 0.3, 0.4],         \"score\": 0.9,     }, ]</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: inference result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.get_metrics","title":"<code>get_metrics()</code>","text":"<p>Get metrics per epoch from metric file.</p> Example <p>hub.get_metrics() [     [         {             \"tag\": \"epoch\",             \"value\": \"1\",         },         {             \"tag\": \"train_loss\",             \"value\": \"0.0012\",         }     ], ]</p> <p>Returns:</p> Type Description <code>list[list[dict]]</code> <p>list[dict]: metrics per epoch</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.get_model_config","title":"<code>get_model_config()</code>","text":"<p>Get model config from model config file.</p> <p>Returns:</p> Name Type Description <code>ModelConfig</code> <code>ModelConfig</code> <p>model config</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.get_train_config","title":"<code>get_train_config()</code>","text":"<p>Get train config from train config file.</p> <p>Returns:</p> Name Type Description <code>TrainConfig</code> <code>TrainConfig</code> <p>train config</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.inference","title":"<code>inference(source, recursive=True, image_size=None, letter_box=None, batch_size=4, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0', draw=False, hold=True)</code>","text":"<p>Start Inference</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>source directory</p> required <code>recursive</code> <code>bool</code> <p>recursive. Defaults to True.</p> <code>True</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. None for using training config. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. None for using training config. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>draw</code> <code>bool</code> <p>draw. Defaults to False.</p> <code>False</code> <code>hold</code> <code>bool</code> <p>hold. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> Example <p>inference_result = hub.inference(         source=\"path/to/images\",         batch_size=4,         image_size=640,         letterbox=False,         confidence_threshold=0.25,         iou_threshold=0.5,         workers=4,         device=\"0\",         draw=True,     )</p> <p>Returns:</p> Name Type Description <code>InferenceResult</code> <code>InferenceResult</code> <p>inference result</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.inference--or-simply-use-train-option-by-passing-none","title":"or simply use train option by passing None","text":"<p>inference_result = hub.inference(         ...         image_size=None,  # use train option         letterbox=None,  # use train option         ...     ) inference_result.predictions [{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.load","title":"<code>load(name, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Load Hub by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>hub name.</p> required <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if hub is not exist in root_dir</p> <p>Returns:</p> Name Type Description <code>Hub</code> <code>BaseHub</code> <p>Hub instance</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.base_hub.BaseHub.train","title":"<code>train(dataset_path, epochs=None, batch_size=None, image_size=None, learning_rate=None, letter_box=None, pretrained_model=None, device='0', workers=2, seed=0, verbose=True, hold=True)</code>","text":"<p>Start Train</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>dataset path</p> required <code>epochs</code> <code>int</code> <p>number of epochs. None to use default. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>batch size. None to use default. Defaults to None.</p> <code>None</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. None to use default. Defaults to None.</p> <code>None</code> <code>learning_rate</code> <code>float</code> <p>learning rate. None to use default. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. None to use default. Defaults to None.</p> <code>None</code> <code>pretrained_model</code> <code>str</code> <p>pretrained model. None to use default. Defaults to None.</p> <code>None</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>workers</code> <code>int</code> <p>number of workers. Defaults to 2.</p> <code>2</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 0.</p> <code>0</code> <code>verbose</code> <code>bool</code> <p>verbose. Defaults to True.</p> <code>True</code> <code>hold</code> <code>bool</code> <p>hold process. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if trained artifact exists.</p> <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>ValueError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> Example <p>train_result = hub.train(         dataset_path=dataset_path,         epochs=100,         batch_size=16,         image_size=640,         learning_rate=0.001,         letterbox=False,         device=\"0\",         workers=2,         seed=123     ) train_result.best_ckpt_file hubs/my_hub/weights/best_ckpt.pt train_result.metrics [[{\"tag\": \"epoch\", \"value\": 1}, {\"tag\": \"train/loss\", \"value\": 0.1}, ...], ...]</p> <p>Returns:</p> Name Type Description <code>TrainResult</code> <code>TrainResult</code> <p>train result</p>"},{"location":"waffle_hub/hub/result/","title":"Result","text":""},{"location":"waffle_hub/hub/result/#trainresult","title":"TrainResult","text":"<p>         Bases: <code>BaseSchema</code></p>"},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.TrainResult.best_ckpt_file","title":"<code>best_ckpt_file: str = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.TrainResult.last_ckpt_file","title":"<code>last_ckpt_file: str = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.TrainResult.metrics","title":"<code>metrics: list[list[dict]] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#evaluateresult","title":"EvaluateResult","text":"<p>         Bases: <code>BaseSchema</code></p>"},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.EvaluateResult.metrics","title":"<code>metrics: list[dict] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#inferenceresult","title":"InferenceResult","text":"<p>         Bases: <code>BaseSchema</code></p>"},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.InferenceResult.predictions","title":"<code>predictions: list[dict[list]] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.InferenceResult.draw_dir","title":"<code>draw_dir: str = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_hub/hub/result/#exportresult","title":"ExportResult","text":"<p>         Bases: <code>BaseSchema</code></p>"},{"location":"waffle_hub/hub/result/#waffle_hub.schema.result.ExportResult.export_file","title":"<code>export_file: str = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"waffle_menu/","title":"Waffle Menu (private)","text":"<p><code>Waffle Menu</code> provide advanced deeplearning applications. <code>Waffle Menu</code> is based on <code>Waffle Hub</code>.</p>"},{"location":"waffle_menu/#active-learning","title":"Active Learning","text":""},{"location":"waffle_menu/active_learning/","title":"Active Learning Base Class","text":"<p>all active learning methods are inherited from <code>ActiveLearning</code> class. Only initialize methods are different. It means that you can use any active learning method by calling sample method of <code>ActiveLearning</code> class.</p>"},{"location":"waffle_menu/active_learning/#waffle_menu.active_learning.active_learning.ActiveLearning.sample","title":"<code>sample(image_dir, num_images, result_dir, save_images=True, hold=True)</code>","text":"<p>Sample images from the image directory</p> <p>Parameters:</p> Name Type Description Default <code>sampled_image_dir</code> <code>Union[Path, str]</code> <p>image directory</p> required <code>num_images</code> <code>int</code> <p>number of images to sample</p> required <code>result_dir</code> <code>Union[Path, str]</code> <p>result directory</p> required <code>save_images</code> <code>bool</code> <p>save sampled images. Defaults to True.</p> <code>True</code> <code>hold</code> <code>bool</code> <p>hold process. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>result directory</p>"},{"location":"waffle_menu/active_learning/#randomsampling","title":"RandomSampling","text":"<p>         Bases: <code>ActiveLearning</code></p>"},{"location":"waffle_menu/active_learning/#waffle_menu.active_learning.method.random.RandomSampling.__init__","title":"<code>__init__(seed=0)</code>","text":""},{"location":"waffle_menu/active_learning/#entropysampling","title":"EntropySampling","text":"<p>         Bases: <code>ActiveLearning</code></p>"},{"location":"waffle_menu/active_learning/#waffle_menu.active_learning.method.entropy.EntropySampling.__init__","title":"<code>__init__(hub, image_size=None, letter_box=None, batch_size=32, num_workers=4, device='0')</code>","text":""},{"location":"waffle_menu/active_learning/#pl2nsampling","title":"PL2NSampling","text":"<p>         Bases: <code>ActiveLearning</code></p>"},{"location":"waffle_menu/active_learning/#waffle_menu.active_learning.method.pl2n.PL2NSampling.__init__","title":"<code>__init__(hub, diversity_sampling=False, image_size=None, letter_box=None, batch_size=32, num_workers=4, device='0')</code>","text":"<p>PL2N Sampling</p> <p>Parameters:</p> Name Type Description Default <code>hub</code> <code>BaseHub</code> <p>Hub</p> required <code>diversity_sampling</code> <code>bool</code> <p>Diversity sampling. Defaults to False.</p> <code>False</code> <code>image_size</code> <code>int</code> <p>Image size. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>Letter box. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Batch size. Defaults to 32.</p> <code>32</code> <code>num_workers</code> <code>int</code> <p>Number of workers. Defaults to 4.</p> <code>4</code> <code>device</code> <code>str</code> <p>Device. Defaults to \"0\".</p> <code>'0'</code>"}]}